---
title: "CSE 120 - Computer Architecture Notes (In Progress)"
excerpt_separator: "<!--more-->"
classes: "wide"
categories:
  - Notes

tags:
  - computer architecture
  - 
---

**Moore's Law** is the observation that the number of transistors per chip in an economical IC doubles approximately every *18-24 months*.

**Dennard Scaling(1974)** $\to$ observation that voltage and current *should* be proportional to the linear dimensions of a transistor. As transistors shrank, so did the necessary voltage and curent because power is proportional to the area of the transistor.
- A way of scaling transistor parameters (including voltage) to keep power density constant
- Ignored *leakage current* (when a transistor is sitting idle, how much current is it leaking) and *threshold voltage* (minimum amount of voltage needed to turn a transistor on and off, doesn't scale well past below 65nm), which caused the end of dennard scaling, which has led to flatline in clock speed of CPUs @ ~4.5 GHz.

CPUs haven't improved much at single core performance, most gains come from having multiple cores, parallelism, speculative prediction, etc, all of which give a performance boost beyond transistor constraints.
  

**Dynamic Power** dissipation of $\alpha * C * f * V^2$ where
- $\alpha$ = percent time switch
- $C$  = capacitance
- $f$ = frequency
- $V$ = Voltage  
As the size of the transistors shrunk, voltage was reduced which allowed circuits to operate at higher frequencies at the same power.(Intuitively, if both $C$ and $V$ decrease, we can increase $f$)

<p align="center">
  <img src="/images/cse120/dennard_scaling.png" width = "100%">
</p>

**Latency** $\to$ interval between stimulation and response (execution time)  
**Throughput** $\to$ total work done per unit of time (e.g. queries/sec). Throughput = $\frac{1}{Latency}$ when we can't do tasks in parallel

**clock period**  $\to$ duration of a clock cycle (basic unit of time for computers)  
**clock frequency** $\to$ $\frac{1}{T_p}$ where $T_p$ is the time for one clock period in seconds.

**Execution time**  = $\frac{C_{pp} * C_{ct}}{C_r}$, $C_{pp}$ = Cycles per program, $C_{ct}$ = Clock cycle time, ${C_r}$ = clock rate
We decrease execution time by either increasing clock rate or decreasing the number of clock cycles.

**Performance** For a machine $A$ running a program $P$ (where higher is faster):
$Perf(A,P) = \frac{1}{Time(A,P)}$  
$Perf(A,P) > Perf(B,P) \to Time(A,P) < Time(B, P)$  
$\frac{Perf(A,P)}{Perf(B,P)} = \frac{Time(B,P)}{Time(A,P)} = n$, where $A$ is $n$ times faster than B when $n > 1$.  
$Speedup = \frac{Time(old)}{Time(new)}$

**Little's Law** $\to Parellelism = Throughput * Latency$

- CPU TIME $\to$ the actual time the CPU spends computing for a specific task.
  - *user cpu time* $\to$ the CPU time spent in a program itself
  - *system CPU time* $\to$ The CPU time spent in the operating system performing tasks on
behalf of the program.

**Clock cycles per instructions(CPI)** $\to$ is the average number of clock cycles each instruction takes to execute. We use *CPI* as an average of all the instructions executed in a program, which accounts for different instructions taking different amounts of time.

$CPU\ Time = I_c * CPI * C_{ct}$ where $I_c = $ instruction count and $C_{ct} =$ clock cycle time.
$CPU\ Time = \frac{I_c * CPI}{C_r}$ where $C_r$ = clock rate. Clock rate is the inverse of clock cycle time.

Measuring performance of a CPU requires us to know the number of instrutions, the clock cycles per instruction, and the clock cycle time. We can measure instruction count by using software tools that profile the execution, or we can use hardware counters which can record the number of instructions executed. Instruction count depends on the architecture, but not the exact implementation. CPI is much more difficult to measure, because it relies on a wide variety of design details in the computer (like the memory and processor structure), as well as the mix of different instruction types executed in an application. As a result, CPI varies by application, as well as implementations of with the same instruction set. 

Given $n$ processors, $Speedup_n = \frac{T_1}{T_n}$, $T_1 > 1$ is the execution time one *one core*, $T_n$ is the execution time on $n$ cores.  
  -$Speedup\ efficiency_n \to Efficiency_n = \frac{Speedup_n}{n}$

- **Amdahl's Law** $\to$ a harsh reality for parallel computing.
  - $Speedup_n = \frac{T_1}{T_n} = \frac{1}{\frac{F_{parallel}}{n} + F_{sequential}} = \frac{1}{\frac{F_{parallel}}{n} +\ (1-F_{parallel})} $
  - using $n$ cores will result in a speedup of $n$ times over 1 core $\to$ **FALSE**
  - states that some fraction of total operation is inherently sequential and impossible to parallelize (like reading data, setting up calculations, control logic, and storing results). Think sequential operation like RNNs and LSTMs.
<p align="center">
  <img src="/images/cse120/amdahl_law_visual.png" width = "80%">
</p>


  
  